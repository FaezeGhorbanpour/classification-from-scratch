{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the name of God\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('ML_HW2_Question7/train.csv')\n",
    "test = pd.read_csv('ML_HW2_Question7/test.csv')\n",
    "y = train.pop('SalePrice')\n",
    "test_id = test.pop('Id').values\n",
    "train_id = train.pop('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artery', 'Feedr', 'Norm', 'PosA', 'PosN', 'RRAe', 'RRAn', 'RRNe', 'RRNn']"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train['Condition1'])\n",
    "list(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_matrix(matrix):\n",
    "    cols = matrix.columns\n",
    "    types = matrix.dtypes\n",
    "    obj_columns = [cols[i] for i in range(len(cols)) if types[i] == 'object']\n",
    "    preprocessed_matrix = pd.get_dummies(matrix, columns = obj_columns, prefix=obj_columns)\n",
    "\n",
    "    return preprocessed_matrix.values, preprocessed_matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preprocessed_train, train_cols = preprocess_matrix(train)\n",
    "n, m = preprocessed_train.shape\n",
    "matrix = np.ones((n,m+1))\n",
    "matrix[:, 1:] = preprocessed_train\n",
    "preprocessed_test, test_cols = preprocess_matrix(test)\n",
    "\n",
    "\n",
    "\n",
    "where_are_NaNs = np.isnan(matrix)\n",
    "matrix[where_are_NaNs] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_error_sse(w, y, matrix):\n",
    "    xw = np.dot(matrix, w)\n",
    "    return np.sum(np.subtract(xw, y)**2)\n",
    "\n",
    "def calculate_w(matrix, y):\n",
    "    w3 = np.dot(np.dot(la.pinv(np.dot(matrix.T, matrix)),matrix.T), y)\n",
    "    return w3\n",
    "\n",
    "\n",
    "def calculate_w_l2(matrix, y, landa):\n",
    "    w = np.dot(np.dot(la.pinv(np.add(np.dot(matrix.T, matrix), landa * np.identity(matrix.shape[1]))),matrix.T), y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffled_train = train.sample(frac=1).reset_index(drop=True)\n",
    "import numpy.linalg as la\n",
    "offset = matrix.shape[0]//10\n",
    "ranges = [10**i for i in range(-10,11)]\n",
    "sses = []\n",
    "ws = []\n",
    "for j in ranges:\n",
    "    sse_sum = 0\n",
    "    ws_sum = 0\n",
    "    for i in range(0, matrix.shape[0], offset):\n",
    "        train_matrix = np.concatenate((matrix[0:i], matrix[i+offset:]))\n",
    "        train_y = np.concatenate((y[0:i],y[i+offset:]))\n",
    "        \n",
    "        validation_matrix = matrix[i:i+offset]\n",
    "        validation_y = y[i:i+offset]\n",
    "        w = calculate_w_l2(train_matrix, train_y, j)\n",
    "        ws_sum += w\n",
    "        sse = calculate_error_sse(w, validation_y, validation_matrix)\n",
    "        sse_sum += sse\n",
    "    sse_average = sse_sum / 5\n",
    "    w_average = ws_sum / 5\n",
    "    sses.append(sse_average)\n",
    "    ws.append(w_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[704778994887.6139, 704771150721.634, 704595837681.3785, 703773829725.8079, 704442157096.0166, 694394106593.0865, 615072401937.0681, 421583280695.15857, 378538019061.33606, 359973235298.8895, 320947238509.3831, 298489118199.14154, 311007034686.7234, 378086899869.1984, 469752389260.8617, 503561580415.54767, 564918599660.8558, 605961522417.1735, 659195511026.9766, 979772940890.8438, 2193679016023.9426]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "min_sse = min([i for i in sses if i != min(sses)])\n",
    "print(sses)\n",
    "min_sse_index = sses.index(min_sse)\n",
    "\n",
    "landa =  ranges[min_sse_index]\n",
    "print(landa)\n",
    "w = calculate_w_l2(matrix, y, landa) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 270)\n",
      "(289,)\n",
      "(1460, 288)\n"
     ]
    }
   ],
   "source": [
    "preprocessed_test, felan = preprocess_matrix(test)\n",
    "print(preprocessed_test.shape)\n",
    "print(w.shape)\n",
    "print(preprocessed_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_w = np.zeros((preprocessed_test.shape[1]+1,))\n",
    "j = 1\n",
    "new_w[0] = w[0]\n",
    "for i in range(len(train_cols)):\n",
    "    if train_cols[i] in test_cols:\n",
    "        new_w[j] = w[i+1]\n",
    "        j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = preprocessed_test.shape\n",
    "matrix = np.ones((n,m+1))\n",
    "matrix[:, 1:] = preprocessed_test\n",
    "\n",
    "test_y = np.dot(matrix, new_w)\n",
    "\n",
    "where_are_NaNs = np.isnan(test_y)\n",
    "test_y[where_are_NaNs] = np.average([test_y[i] for i in range(len(test_y)) if not where_are_NaNs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "percentile_list = pd.DataFrame(\n",
    "    {'Id': test_id,\n",
    "     'SalePrice': test_y,\n",
    "    })\n",
    "percentile_list.to_csv('resule.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
